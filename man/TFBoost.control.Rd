% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/TREEBOOST.R
\name{TFBoost.control}
\alias{TFBoost.control}
\title{Tuning and control parameters for the tree-based functional boosting algorithm}
\usage{
TFBoost.control(
  make_prediction = TRUE,
  tree_control = TREE.control(),
  loss = "l2",
  user_func = NULL,
  shrinkage = 0.05,
  precision = 4,
  init_type = "mean",
  nknot = 3,
  save_f = FALSE,
  trace = FALSE,
  save_tree = FALSE
)
}
\arguments{
\item{make_prediction}{logical indicating whether to make predictions using \code{x_test} (defaults to \code{TRUE})}

\item{tree_control}{control parameters for the tree learner of TFBoost (defaults to \code{TREE.control()}, see \code{\link{TREE.control}})}

\item{loss}{loss function of TFBoost (character, 'l2' or 'lad', defaults to 'l2')}

\item{user_func}{list of the loss, gradient of the loss, and initialization function of TFBoost, required when \code{loss} parameter is missing (list, defaults to \code{NULL})}

\item{shrinkage}{shrinkage parameter in boosting (numeric, defaults to 0.05)}

\item{precision}{number of significant digits to keep when using validation error to calculate early stopping time (numeric, defaults to 4)}

\item{init_type}{type of initialization for TFBoost, at the mean or median of the training responses (character, 'mean' or 'median', defaults to 'mean')}

\item{nknot}{number of interior knots of the cubic B-spline basis (numeric, defaults to 3)}

\item{save_f}{logical indicating whether to save the function estimates at all iterations (defaults to \code{FALSE})}

\item{trace}{logical indicating whether to print the number of completed iterations for monitoring progress (defaults to \code{FALSE})}

\item{save_tree}{logical indicating whether to save the tree objects at all iterations, required when the user calls \code{TFBoost.predict} with the returned object from \code{TFBoost} (defaults to \code{FALSE})}
}
\value{
A list of all input parameters
}
\description{
Tuning and control parameters for the TFBoost algorithm.
}
\details{
Various tuning and control parameters for the \code{\link{TFBoost}} algorithm implemented in the
function
}
\author{
Xiaomeng Ju, \email{xiaomeng.ju@stat.ubc.ca}

#' @examples
\dontrun{
data(GED)
n <- nrow(GED$price) 
n0 <- floor( 0.2 * n) 
set.seed(123)
idx_test <- sample(n, n0)
idx_train <- sample((1:n)[-idx_test], floor( 0.6 * n ) )
idx_val <- (1:n)[ -c(idx_test, idx_train) ] 
xtrain <- GED$price[idx_train, ]
ytrain <- GED$demand[idx_train ]
xval <- GED$price[idx_val, ]
yval <- GED$demand[idx_val ]
xtest <- GED$price[idx_test, ]
ytest <- GED$demand[idx_test ]
gg <- 1:24  
tt <- c(0,24) 
niter <- 1000
my.control <- TFBoost.control(make_prediction = TRUE, 
tree_control = TREE.control(tree_type  = "B", d = 1, num_dir = 200), 
shrinkage = 0.05, nknot = 3, loss = "l2")

model_TFBoost <- TFBoost(x_train = xtrain, y_train = ytrain,  x_val = xval,  y_val = yval, 
       x_test = xtest, y_test = ytest, grid = gg, t_range  = tt, niter = niter, 
       control = my.control)
}
}
